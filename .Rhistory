set.seed(1)
tune.out=tune(svm ,binaryv∼.,data=Auto[,-1],kernel="linear", ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,100) ))
require(e1071)
set.seed(1)
tune.out=tune(svm ,binaryv∼.,data=Auto[,-1],kernel="linear", ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,100) ))
summary(tune.out)
tune.out.radial=tune(svm ,binaryv∼.,data=Auto[,-1],kernel="radial", ranges=list(cost=c(0.1, 1,10,100,1000),gamma=c(0.5,1,2,3,4))) ))
tune.out.radial=tune(svm ,binaryv∼.,data=Auto[,-1],kernel="radial", ranges=list(cost=c(0.1, 1,10,100,1000),gamma=c(0.5,1,2,3,4))) )
tune.out.radial=tune(svm ,binaryv∼.,data=Auto[,-1],kernel="radial", ranges=list(cost=c(0.1, 1,10,100,1000),gamma=c(0.5,1,2,3,4)))
summary(tune.out.radial)
tune.out.poly=tune(svm ,binaryv∼.,data=Auto[,-1],kernel="radial", ranges=list(cost=c(0.1, 1,10,100,1000),degree=c(1,2,3,4)))
tune.out.poly=tune(svm ,binaryv∼.,data=Auto[,-1],kernel="polynomial", ranges=list(cost=c(0.1, 1,10,100,1000),degree=c(1,2,3,4)))
summary(tune.out.poly)
tune.out=tune(svm ,binaryv~.,data=Auto[,-1],kernel="linear", ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,100) ))
tune.out.radial=tune(svm ,binaryv~.,data=Auto[,-1],kernel="radial", ranges=list(cost=c(0.1, 1,10,100,1000),gamma=c(0.5,1,2,3,4)))
tune.out.poly=tune(svm ,binaryv~.,data=Auto[,-1],kernel="polynomial", ranges=list(cost=c(0.1, 1,10,100,1000),degree=c(1,2,3,4)))
library(ISLR)
attach(OJ)
fix(OJ)
str(OJ)
fix(OJ)
?OJ
fix(OJ)
library(ISLR)
attach(OJ)
train=sample(seq_len(nrow(OJ)),size = 800)
traindata=OJ[train,]
testdata=OJ[-train,]
svm.fit=svm(Purchase~.,data = traindata,kernel="linear",cost=0.01)
summary(svm.fit)
?svm
ypred=predict(svm.fit,data=traindata)
table(predict=ypred,truth=traindata$Purchase)
ypred1=predict(svm.fit,data=testdata)
table(predict=ypred1,truth=testdata$Purchase)
str(ypred1)
dim(testdata)
dim(OJ)
ypred1=predict(svm.fit,testdata)
table(predict=ypred1,truth=testdata$Purchase)
tune.out1=tune(svm,Purchase~.,data = traindata,kernel="linear",ranges=list(cost=c(0.01, 0.1, 1,5,10)))
summary(tune.out1)
tune.out1=tune(svm,Purchase~.,data = OJ,kernel="linear",ranges=list(cost=c(0.01, 0.1, 1,5,10)))
summary(tune.out1)
svm.fit1e=svm(Purchase~.,data = traindata,kernel="linear",cost=5)
#Training error
ypred2=predict(svm.fit1e,data=traindata)
table(predict=ypred2,truth=traindata$Purchase)
#Test error
ypred3=predict(svm.fit1e,testdata)
table(predict=ypred3,truth=testdata$Purchase)
tune.out.radial2=tune(svm,Purchase~.,data = traindata,kernel="radial", ranges = list(cost=c(0.1, 1,10,100,1000),gamma=c(0.5,1,2,3,4)))
summary(tune.out)
A=matrix(c(2,-3,-6,-1,-3,-3,10,0,-1,-6,-6,0,18,0,-5,-1,-1,0,0,0,-3,-6,-5,0,0)nrow = 5,byrow=T)
A
library("matlib")
Ainv=inv(A)
Ainv
A=matrix(c(2,-3,-6,-1,-3,-3,10,0,-1,-6,-6,0,18,0,-5,-1,-1,0,0,0,-3,-6,-5,0,0),nrow = 5,byrow=T)
A
library("matlib")
Ainv=inv(A)
Ainv
b=matrix(c(4,-5,2,-4,-15))
b
Ainv*b
A=matrix(c(2,-3,-6,-1,-3,-3,10,0,-1,-6,-6,0,18,0,-5,-1,-1,0,0,0,-3,-6,-5,0,0),nrow = 5,byrow=T)
A
library("matlib")
Ainv=inv(A)
Ainv
b=matrix(c(4,-5,2,-4,-15))
b
Ainv*b
A=matrix(c(1,-1,1,-1,1,1,0,0,0,0,1,1,1,1,1,1,2,4,8,16,1,3,9,27,81),nrow = 5,byrow = T)
A
Ainv=inv(A)
Ainv
b=matrix(c(1,-1,2,-1,2))
Ainv*b
A=matrix(c(2,-3,-6,-1,-3,-3,10,0,-1,-6,-6,0,18,0,-5,-1,-1,0,0,0,-3,-6,-5,0,0),nrow = 5,byrow=T)
A
library("matlib")
Ainv=inv(A)
Ainv
b=matrix(c(4,-5,2,-4,-15))
b
Ainv%*%b
det(A)
B=matrix(c(0,0,-1,-1,0,0,0,-3,-6,-5,-1,-3,2,-3,-6,-1,-6,-3,10,0,0,-5,-6,0,18),nrow = 5,byrow = T)
B
det(B)
C=matrix(c(0,0,-1,-1,-3,0,0,-5,-2,-1,-1,-5,2,0,0,-1,-2,0,2,0,-3,-1,0,0,2),nrow = 5,byrow = T)
library("matlib")
det(C)
C
C[3,3]
C[c(1,2,3),c(1,2,3)]
det(C[c(1,2,3),c(1,2,3)])
det(C[c(1,2,3,4),c(1,2,3,4)])
polyroot(c(-1600,10000,-10000))
polyroot(c(-10000,10000,-1600))
polyroot(c(-10000,10000,-1600))-1
polyroot(c(-100,350,-200,800,800,-1000))
polyroot(c(-100,350,-200,800,800,-1000))-1
polyroot(-16000.10000.-10000)
polyroot(c(-16000.10000.-10000)
polyroot(c(-16000.10000.-10000))
polyroot(c(-16000,10000,-10000))
polyroot(c(-1600,10000,-10000))
polyroot(c(-10000,10000,-1600))
polyroot(c(-450000,-42500,92800,38600,614600,-202200))
polyroot(c(-450000,-42500,92800,38600,614600,-202200))-1
polyroot(c(-450000,-42500,92800,386000,614600,-202200))-1
polyroot(c(-202200,614600,386000,92800,-42500,-450000))-1
polyroot(c(400000,350000,300000,250000,200000,150000,-2400000,100000,300000,500000))-1
polyroot(c(-1300000,200000,200000,200000,200000,200000,200000,200000,200000,200000,200000,-520000))
polyroot(c(-1300000,200000,200000,200000,200000,200000,200000,200000,200000,200000,200000,-520000))-1
polyroot(c(-1300000,200000,200000,200000,200000,200000,200000,200000,200000,200000,-520000))-1
polyroot(c(400000,
350000,
300000,
250000,
200000,
150000,
-2400000,
100000,
300000,
500000,
0,
))
polyroot(c(400000,
350000,
300000,
250000,
200000,
150000,
-2400000,
100000,
300000,
500000,
0))
polyroot(c(400000,
350000,
300000,
250000,
200000,
150000,
-2400000,
100000,
300000,
500000,
0))-1
polyroot(c(-1300000,
200000,
200000,
200000,
200000,
200000,
200000,
200000,
200000,
200000,
-520000
))-1
polyroot(c(100,
200,
300,
400,
500,
600,
-1810,
30,
60,
90,
120
))-1
polyroot(c(4,-1,6,-5))-1
library("ggbiplot")
library(devtools)
install_github("vqv/ggbiplot")
library(ggbiplot)
library("ggbiplot")
library(ggbiplot)
getwd()
setwd("C:\Users\mehta\Desktop\Spring2019\ISEN614\Project")
setwd("C:/Users/mehta/Desktop/Spring2019/ISEN614/Project")
read.csv("Project_dataset.csv")
read.csv("Project_dataset.csv",header = F)
df=read.csv("Project_dataset.csv",header = F)
str(df)
as.numeric(df)
df[1,]=as.numeric(df[1,])
readxl::excel_sheets("Project_dataset.xlsx")
df[1,]
df[,1]
df=read.csv("Project_dataset.csv",header = F)
df[1:5,]
str(df)
df[,1]=as.numeric(df[,1])
str(df[,1])
df=read.csv("Project_dataset.csv",header = F)
readxl::read_excel("Project_dataset.xlsx")
readxl::read_excel("Project_dataset.xlsx",header = F)
?read_excel
read_xlsx("Project_dataset.xlsx,col_names=F")
readxl::read_xlsx("Project_dataset", col_names = F)
readxl::read_xlsx("Project_dataset.xlsx", col_names = F)
df=readxl::read_xlsx("Project_dataset.xlsx", col_names = F)
str(df)
range(df)
range(df[,c(1,2,3)])
?ggplot
library(ggplot)
library("ggplot")
install.packages("ggplot")
library(ggplot2)
?ggplot
ggplot(df,aes(x = dens, fill = lines)) + geom_density(alpha = 0.5))
ggplot(df,aes(x = dens, fill = lines) + geom_density(alpha = 0.5))
ggplot(df, aes(x = dens, fill = lines)) + geom_density(alpha = 0.5)
ggplot(df, aes(x = "dens", fill = lines)) + geom_density(alpha = 0.5)
?ggplot
ggplot(df)
scale(df)
df1=scale(df)
str(df1)
df1=scale(df[,1])
str(df1)
?scale
df1=scale(df)
colMeans(df)
colMeans(df1)
ggplot(df1)
str(df1)
library(caret)
df1=preProcess(df[,c(1:209)])
str(df1)
df1
df1
newdf=predict(df1,df[,c(1:209)])
str(newdf)
ggplot(preProcess(df))
df.pca=prcomp(df[,c(1:209)],center = TRUE,scale = T)
?prcomp
prcomp(df, center = T, scale. = T)
summary(prcomp(df, center = T, scale. = T))
summary(prcomp(df, center = F, scale. = F))
library("FactoMineR")
install.packages("FactoMineR")
library(FactoMineR)
df2=PCA(df,graph = F)
df2$eig
?PCA
df2=PCA(df,scale.unit = F,graph = F)
df2$eig
df2=PCA(df,scale.unit = F,graph = T)
df2$var
str(df2$var)
df2$eig
?PCA
df2$var$coord
help("Chisquare")
?chisq.test
?PCA
df2=PCA(df,scale.unit = F,graph = T)
df2$eig
library(gdata)
library(readxl)
library(RSpectra)
library(EnvStats)
getwd()
setwd("C:/Users/mehta/Desktop/Spring2019/ISEN614/Project")
install.packages("RSpectra")
install.packages("EnvStats")
library(gdata)
library(readxl)
library(RSpectra)
library(EnvStats)
p=read_xlsx("Project_dataset.xlsx", col_names= FALSE)
data_set=p
summary(data_set)
dim(data_set)
#checking missing values
miss_vals=c()
for(x in 1:ncol(data_set)){
p=sum(is.na(data_set[,x]))
miss_vals=c(miss_vals,p)
}
miss_vals
#Percentage of variance explained:
var_perc=sum(res$values[1:3])/sum(res$values)
var_perc
#summary(data_set)
#plot(data_set[,1])
#hist(data_set[,1])
#lines(density(data_set[,1]))
#p=as.data.frame(data_set1)
#dim(p)
#ggplot(p, aes(x=p[,3]))+geom_histogram(aes(y = ..density..),
#                                                              binwidth = 2.5, colour = "blue", fill = "white")
#curve(dnorm(x, mean=m, sd=s),col="Red",add=TRUE)
#---------------------
cor(data_set)
par(mfrow=c(2,5))
x=data_set1
for(i in 1:ncol(data_set1)){
m=mean(data_set1[,i])
s=sd(data_set1[,i])
hist(data_set1[,i], freq=FALSE, breaks=8, col="White")
curve(dnorm(x, mean=m, sd=s),col="Red",add=TRUE)
}
m=mean(data_set1[,1])
a=c(i)
for (i in 1:10){
a=c(i)
}
a
t=c()
for (i in 1:10){
t=c(i)
}
t
t=as.data.frame()
for (i in 1:10){
t[i,1]=c(i)
}
t
?seq
t=as.data.frame(c(seq(1,10,1)))
for (i in 1:10){
t[i,1]=c(i)
}
t
?runif
t=as.data.frame(c(runif(10,0,1))))
for (i in 1:10){
t[i,1]=c(i)
}
t
t=as.data.frame(c(runif(10,0,1))))
t
for (i in 1:10){
t[i,1]=c(i)
}
t
t=as.data.frame(c(runif(10,0,1)))
t
for (i in 1:10){
t[i,1]=c(i)
}
t
df=readxl::read_xlsx("Project_dataset.xlsx")
head(df)
df=readxl::read_xlsx("Project_dataset.xlsx",col_names = F)
head(df)
df=as.dataframe(readxl::read_xlsx("Project_dataset.xlsx",col_names = F))
df=as.data.frame(readxl::read_xlsx("Project_dataset.xlsx",col_names = F))
head(df)
str(df)
df
df1=as.matrix(df)
df1_cov=cov(df1)
str(df1_cov)
?eigen
?pca
?PCA
?prcomp
e=prcomp(df1_cov)
e$rotation
e
ev=cbind(e$rotation[,1:4])
ev
t(ev[,1])
library(matlib)
dim(df)
ps1=t(ev[,1])%*%t(df[1,])%*%ev[,1]
ps1=t(ev[,1])%*%t(df)
ps1
e$x
df=as.data.frame(readxl::read_xlsx("Project_dataset.xlsx",col_names = F))
df1=as.matrix(df)
df1_cov=cov(df1)
str(df1_cov)
e=prcomp(df1_cov, retx = T)
ev=cbind(e$rotation[,1:4])
library(matlib)
ps1=t(ev[,1])%*%t(df)
e$x
e=prcomp(df1_cov, retx = T, center = F, scale. = F)
ev=cbind(e$rotation[,1:4])
library(matlib)
ps1=t(ev[,1])%*%t(df)
e$x
library(FactoMineR)
?PCA
f=PCA(df1_cov,scale.unit = F,graph = F)
f$eig
dim(df1)
str(df1)
?cov
?PCA
?prcomp
df=as.data.frame(readxl::read_xlsx("Project_dataset.xlsx",col_names = F))
df1=as.matrix(df)
df1_cov=cov(df1)
str(df1_cov)
e=prcomp(df1_cov, retx = T, center = F, scale. = F)
head(e$x)
?cov
e=prcomp(df1, retx = T, center = F, scale. = F)
e$x[1:3,1:2]
a=eigen(df1_cov)
?PCA
f=PCA(df1_cov,graph = F)
f$eig[1:5]
f$eig[1:5,]
f=PCA(df1_cov,graph = F,scale.unit = F)
f$eig[1:4,]
e=prcomp(df1_cov, retx = T, center = F, scale. = F)
e$sdev[1:3,]
e$sdev
sum(e$sdev)
e$x[1:5]
e$x[1:5,]
library(gdata)
library(readxl)
library(RSpectra)
library(EnvStats)
library(matlib)
getwd()
p=read_xlsx("Project_dataset.xlsx", col_names= FALSE)
data_set=p
summary(data_set)
dim(data_set)
#data_set is the original data we have
#checking missing values
miss_vals=c()
for(x in 1:ncol(data_set)){
p=sum(is.na(data_set[,x]))
miss_vals=c(miss_vals,p)
}
miss_vals
#Percentage of variance explained:
var_perc=sum(res$values[1:3])/sum(res$values)
var_perc
#---------------------
#This set of code just shows that all the data attributes follows the normal distribution:
cor(data_set) #Calculates the correlations, can be helpful in report
par(mfrow=c(2,5))
x=data_set1
for(i in 1:ncol(data_set1)){
m=mean(data_set1[,i])
s=sd(data_set1[,i])
hist(data_set1[,i], freq=FALSE, breaks=8, col="White")
curve(dnorm(x, mean=m, sd=s),col="Red",add=TRUE)
}
#--------------------
#--------------------------------
#The PCA Part:
#PCA:
p_cov=cov(data_set)
dim(p_cov)
res=eigs(p_cov,209,which="LM")
eig_vals=res$values
U=res$vectors
#plotting the eigen values"
K_vals=res$values[c(1:4)]
cheg=c()
perc_var=sum(res$values[c(1:4)])/sum(res$values)
perc_var
#Generating the data set from PCA:
U1=U[,c(1:4)]
k=c()
for(i in 1:nrow(data_set)){
x=as.matrix(data_set[i,])
z=x%*%U1
k=as.data.frame(rbind(k,z))
}
dim(k)
#Data set for T^2 chart:
#Covariance and its inverse
t_cov=cov(k)
dim(t_cov)
inv_cov=inv(t_cov)
library(matlib)
inv_cov=inv(t_cov)
install.packages("matlib")
library(matlib)
inv_cov=inv(t_cov)
library(gdata)
library(readxl)
library(RSpectra)
library(EnvStats)
library(matlib)
getwd()
p=read_xlsx("Project_dataset.xlsx", col_names= FALSE)
data_set=p
summary(data_set)
dim(data_set)
miss_vals=c()
miss_vals=c()
for(x in 1:ncol(data_set)){
p=sum(is.na(data_set[,x]))
miss_vals=c(miss_vals,p)
}
miss_vals
res
var_perc=sum(res$values[1:3])/sum(res$values)
cor(data_set)
par(mfrow=c(2,5))
x=data_set1
